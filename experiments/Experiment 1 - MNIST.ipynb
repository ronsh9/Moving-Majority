{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea250c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myuhk\\anaconda3\\envs\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import random\n",
    "\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952c7ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, embedding_size=64):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Define the encoder part\n",
    "        self.enc_conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.enc_conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Define the bottleneck part\n",
    "        self.bottleneck_conv = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(7*7*64, embedding_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = F.relu(self.enc_conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.enc_conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = F.relu(self.bottleneck_conv(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d804c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb753efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_dataset):\n",
    "    data = {}\n",
    "    for x in range(10):\n",
    "        data[x] = [data for data in train_dataset if data[1] == x]\n",
    "        random.shuffle(data[x])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07cc921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_biased_dataset(data, probs):\n",
    "    '''\n",
    "    probs: [p_0, p_1, ..., p_9]\n",
    "    returns a biased dataset according to probs\n",
    "    '''\n",
    "    max_p = max(probs)\n",
    "    max_x = np.argmax(probs)\n",
    "    max_n = 0.9 * len(data[max_x])\n",
    "    res = []\n",
    "    for x, lis in data.items():\n",
    "        n = int(max_n * probs[x] / max_p)\n",
    "        res += data[x][:n]\n",
    "    random.shuffle(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "954e8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(dataset):\n",
    "  model.eval() # UNet\n",
    "  return [(model(image.unsqueeze(0)), label) for image, label in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a3b1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\tCPU\n"
     ]
    }
   ],
   "source": [
    "# Getting device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\t\" + (f\"{torch.cuda.get_device_name(0)}\" if torch.cuda.is_available() else \"CPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eade4560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasedRandomForestClassifier(RandomForestClassifier):\n",
    "    def __init__(self,\n",
    "                 n_estimators=100,\n",
    "                 criterion='gini',\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.0,\n",
    "                 max_features='sqrt',\n",
    "                 max_leaf_nodes=None,\n",
    "                 min_impurity_decrease=0.0,\n",
    "                 bootstrap=True,\n",
    "                 oob_score=False,\n",
    "                 n_jobs=None,\n",
    "                 random_state=None,\n",
    "                 verbose=0,\n",
    "                 warm_start=False,\n",
    "                 class_weight=None,\n",
    "                 ccp_alpha=0.0,\n",
    "                 max_samples=None,\n",
    "                n_classes = 10):\n",
    "\n",
    "        super(BiasedRandomForestClassifier, self).__init__(\n",
    "            n_estimators=n_estimators,\n",
    "            criterion=criterion,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_features=max_features,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            bootstrap=bootstrap,\n",
    "            oob_score=oob_score,\n",
    "            n_jobs=n_jobs,\n",
    "            random_state=random_state,\n",
    "            verbose=verbose,\n",
    "            warm_start=warm_start,\n",
    "            class_weight=class_weight,\n",
    "            ccp_alpha=ccp_alpha,\n",
    "            max_samples=max_samples)\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.thresholds = np.array([1/self.n_classes for _ in range(self.n_classes)])\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        return super(BiasedRandomForestClassifier, self).fit(X, y, sample_weight)\n",
    "\n",
    "    def fit_thresholds(self, X, y, alpha = 0.01, batches = 50, sample_weight = None):\n",
    "        X_batches = np.array_split(X, batches)\n",
    "        y_batches = np.array_split(y, batches)\n",
    "        cnt = 0\n",
    "        for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "            cnt += 1\n",
    "            y_pred = self.predict(X_batch)\n",
    "            for y_p, y in zip(y_pred, y_batch):\n",
    "                if y_p != y:\n",
    "                    diff = alpha * self.thresholds[y]\n",
    "                    self.thresholds[y_p] += diff\n",
    "                    self.thresholds[y] -= diff\n",
    "#             print('Batch No: ', cnt, '\\nThresholds: ', self.thresholds)\n",
    "        return self.thresholds\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.argmax(proba - self.thresholds, axis = 1)\n",
    "    \n",
    "    def predict_biased_label_shift(self, X, train_ratios, test_ratios):\n",
    "        proba = self.predict_proba(X)\n",
    "        for i in range(10):\n",
    "            proba[:, i] *= test_ratios[i] / train_ratios[i]\n",
    "        proba /= proba.sum(axis = 1, keepdims = True)\n",
    "        return np.argmax(proba - self.thresholds, axis = 1)\n",
    "    \n",
    "    def predict_biased_online(self, X, y, alpha = 0.01):\n",
    "        res = []\n",
    "        threshold_history = []\n",
    "        for (xi, yi) in zip(X, y):\n",
    "            proba = self.predict_proba([xi])\n",
    "            predicted_class = np.argmax(proba - self.thresholds, axis = 1)[0]\n",
    "            res.append(predicted_class)\n",
    "\n",
    "            threshold_history.append(self.thresholds.copy()) \n",
    "\n",
    "            if predicted_class != yi:\n",
    "                diff = alpha * self.thresholds[yi]\n",
    "                self.thresholds[predicted_class] += diff\n",
    "                self.thresholds[yi] -= diff\n",
    "        return np.array(res), threshold_history\n",
    "    \n",
    "    def predict_biased_online_recall(self, X, y, alpha = 0.1):\n",
    "        res = []\n",
    "\n",
    "        threshold_history = []\n",
    "        for (xi, yi) in zip(X, y):\n",
    "            proba = self.predict_proba([xi])\n",
    "            predicted_class = np.argmax(proba - self.thresholds, axis = 1)[0]\n",
    "            res.append(predicted_class)\n",
    "\n",
    "            threshold_history.append(self.thresholds.copy())\n",
    "\n",
    "            if predicted_class != yi:\n",
    "                new_yi_threshold = (1-alpha)*self.thresholds[yi]\n",
    "                self.thresholds*=((1-new_yi_threshold)/(1-self.thresholds[yi]))\n",
    "                self.thresholds[yi] = new_yi_threshold\n",
    "        return np.array(res), threshold_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a24a3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to draw a graph of majority changes over each iterations\n",
    "\n",
    "def plot_threshold_history(threshold_history):\n",
    "    \"\"\"\n",
    "    Plots the history of threshold values over iterations with distinct colors for each threshold.\n",
    "\n",
    "    Args:\n",
    "    threshold_history (list of list of float): A list where each element \n",
    "                                               is a list of threshold values \n",
    "                                               at a certain iteration.\n",
    "    \"\"\"\n",
    "    # Transpose the threshold_history to get a list for each threshold across all steps\n",
    "    transposed_history = list(zip(*threshold_history))\n",
    "\n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot each threshold's history\n",
    "    for i, history in enumerate(transposed_history):\n",
    "        plt.plot(history, label=f'Threshold {i+1}')\n",
    "\n",
    "    # Labeling the plot\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Threshold Value')\n",
    "    plt.title('Threshold Values Over Iterations')\n",
    "    plt.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d89d016f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Get one batch of images from the train loader\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Select the first image from this batch\n",
    "# The shape of 'image' will be [1, 1, 28, 28], which is what the model expects\n",
    "image = images[0].unsqueeze(0)\n",
    "\n",
    "# Forward pass to get the embedding\n",
    "embedding = model(image)\n",
    "\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2df75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = encode_data([data for data in train_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfb83012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_biased_dataset(balanced_data, ratios):\n",
    "    biased_datasets = {}\n",
    "    encoded_biased_datasets = {}\n",
    "    data = split_data(balanced_data)\n",
    "    n = 10\n",
    "    for ratio in ratios:\n",
    "        probs = [ratio] + [(1 - ratio)/(n - 1)] * (n -1)\n",
    "        biased_datasets[ratio] = create_biased_dataset(data, probs)\n",
    "        encoded_biased_datasets[ratio] = encode_data(biased_datasets[ratio])\n",
    "        \n",
    "    return encoded_biased_datasets\n",
    "\n",
    "ratios = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "encoded_test = make_biased_dataset(test_dataset, ratios)\n",
    "encoded_test_single = make_biased_dataset(test_dataset, [0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18189b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_label_shift(training_dataset, test_datasets):\n",
    "    # Prepare the test data\n",
    "    \n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    ratios = []\n",
    "    og_accuracies = []\n",
    "    og_precisions = []\n",
    "    og_recalls = []\n",
    "    \n",
    "    X_train, y_train = zip(*[(x.detach().numpy().flatten(), y) for x, y in training_dataset])\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    model = BiasedRandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    og = RandomForestClassifier()\n",
    "    og.fit(X_train, y_train)\n",
    "\n",
    "    for ratio, test_dataset in test_datasets.items():\n",
    "        print('Test Bias Ratio: ', ratio)\n",
    "        #print('Fitted thresholds: ', thresholds)\n",
    "        \n",
    "        X_test, y_test = zip(*[(x.detach().numpy().flatten(), y) for x, y in test_dataset])\n",
    "        X_test = np.array(X_test)\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "        predictions = model.predict_biased_label_shift(X_test, [0.1] * 10, [ratio] + [(1-ratio)/9]*9)\n",
    "        accuracies.append(accuracy_score(y_test, predictions))\n",
    "        og_accuracies.append(accuracy_score(y_test, og.predict(X_test)))\n",
    "        og_precisions.append(precision_score(y_test, og.predict(X_test), average='macro'))\n",
    "        og_recalls.append(recall_score(y_test, og.predict(X_test), average='macro'))\n",
    "        precisions.append(precision_score(y_test, predictions, average='macro'))\n",
    "        recalls.append(recall_score(y_test, predictions, average='macro'))\n",
    "        ratios.append(ratio)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ratios, og_accuracies, label='RF Accuracy', color='blue')\n",
    "    plt.plot(ratios, accuracies, label='Label Shift Accuracy', color='red')\n",
    "\n",
    "    plt.xlabel('Fraction of 0')\n",
    "    plt.ylabel('Performance Metrics')\n",
    "    plt.title('Performance Metrics for Different Sample Ratios')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ratios, og_precisions, label='RF Precision', color='blue')\n",
    "    plt.plot(ratios, precisions, label='Label Shift Precision', color='red')\n",
    "\n",
    "    plt.xlabel('Fraction of 0')\n",
    "    plt.ylabel('Performance Metrics')\n",
    "    plt.title('Performance Metrics for Different Sample Ratios')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ratios, og_recalls, label='RF Recall', color='blue')\n",
    "    plt.plot(ratios, recalls, label='Label Shift Recall', color='red')\n",
    "\n",
    "    plt.xlabel('Fraction of 0')\n",
    "    plt.ylabel('Performance Metrics')\n",
    "    plt.title('Performance Metrics for Different Sample Ratios')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "935c40d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_online(training_dataset, test_datasets):\n",
    "    # Prepare the test data\n",
    "    \n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    ratios = []\n",
    "    og_accuracies = []\n",
    "    og_precisions = []\n",
    "    og_recalls = []\n",
    "    \n",
    "    X_train, y_train = zip(*[(x.detach().numpy().flatten(), y) for x, y in training_dataset])\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    model = BiasedRandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    og = RandomForestClassifier()\n",
    "    og.fit(X_train, y_train)\n",
    "\n",
    "    for ratio, test_dataset in test_datasets.items():\n",
    "        print('Test Bias Ratio: ', ratio)\n",
    "        #print('Fitted thresholds: ', thresholds)\n",
    "        \n",
    "        X_test, y_test = zip(*[(x.detach().numpy().flatten(), y) for x, y in test_dataset])\n",
    "        X_test = np.array(X_test)\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "        predictions = model.predict_biased_online_recall(X_test, y_test, alpha = 0.1)[0] # chage this to \n",
    "        accuracies.append(accuracy_score(y_test, predictions))\n",
    "        og_accuracies.append(accuracy_score(y_test, og.predict(X_test)))\n",
    "        og_precisions.append(precision_score(y_test, og.predict(X_test), average='macro'))\n",
    "        og_recalls.append(recall_score(y_test, og.predict(X_test), average='macro'))\n",
    "        precisions.append(precision_score(y_test, predictions, average='macro'))\n",
    "        recalls.append(recall_score(y_test, predictions, average='macro'))\n",
    "        ratios.append(ratio)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ratios, og_accuracies, label='RF Accuracy', color='blue')\n",
    "    plt.plot(ratios, accuracies, label='DeBOT Accuracy', color='red')\n",
    "\n",
    "    plt.xlabel('Fraction of 0')\n",
    "    plt.ylabel('Performance Metrics')\n",
    "    plt.title('Performance Metrics for Different Sample Ratios')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ratios, og_precisions, label='RF Precision', color='blue')\n",
    "    plt.plot(ratios, precisions, label='DeBOT Precision', color='red')\n",
    "\n",
    "    plt.xlabel('Fraction of 0')\n",
    "    plt.ylabel('Performance Metrics')\n",
    "    plt.title('Performance Metrics for Different Sample Ratios')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ratios, og_recalls, label='RF Recall', color='blue')\n",
    "    plt.plot(ratios, recalls, label='DeBOT Recall', color='red')\n",
    "\n",
    "    plt.xlabel('Fraction of 0')\n",
    "    plt.ylabel('Performance Metrics')\n",
    "    plt.title('Performance Metrics for Different Sample Ratios')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35fed904",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models_online(encoded_train, encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4794ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
